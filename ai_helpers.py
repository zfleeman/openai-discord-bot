"""
Helper functions that interact with OpenAI
"""

from configparser import ConfigParser
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple

from openai import AsyncOpenAI
from openai.types.responses import Response

from db_utils import CommandContext, get_api_key, get_response_id, update_chat


def get_config():
    """
    Read the configuration specified in the config ini
    """
    config = ConfigParser()
    config.read("config.ini")
    return config


async def get_openai_client(guild_id: int) -> AsyncOpenAI:
    """
    Return the guild-assigned API key
    """
    api_key = await get_api_key(guild_id=guild_id)
    openai_client = AsyncOpenAI(api_key=api_key)

    return openai_client


async def new_response(
    context: CommandContext,
    prompt: str,
    openai_client: Optional[AsyncOpenAI] = None,
    model: str = "gpt-4o-mini",
) -> Response:
    """
    Generate a new response with the OpenAI Response API and store its ID
    """
    config = get_config()

    # topic-specific models
    if context.params.get("topic") == "talk_quotes":
        model = "gpt-4o"

    # use command-specified custom instructions --> for future commands
    instructions = context.params.get("custom_instructions") or config.get(
        "OPENAI_INSTRUCTIONS", context.params.get("topic")
    )

    # limit the response output to conform to Discord character limit
    max_output_tokens = config.getint("OPENAI_GENERAL", "max_output_tokens", fallback=500)

    if not openai_client:
        openai_client = await get_openai_client(guild_id=context.guild_id)

    previous_response_id = await get_response_id(context=context)

    response = await openai_client.responses.create(
        input=prompt,
        model=model,
        instructions=instructions,
        previous_response_id=previous_response_id,
        max_output_tokens=max_output_tokens,
    )

    await update_chat(response_id=response.id, context=context)

    return response


async def generate_speech(
    context: CommandContext,
    file_name: str,
    tts: str,
    voice: str = "onyx",
    openai_client: Optional[AsyncOpenAI] = None,
) -> Path:
    """
    Use OpenAI's Speech API to create a text-to-speech audio file
    """
    config = get_config()

    if not openai_client:
        openai_client = await get_openai_client(guild_id=context.guild_id)

    async with openai_client.audio.speech.with_streaming_response.create(
        model=config.get("OPENAI_GENERAL", "speech_model", fallback="tts-1"),
        voice=voice,
        input=tts,
        response_format=config.get("OPENAI_GENERAL", "speech_file_format", fallback="wav"),
    ) as speech:
        file_path = content_path(context=context, file_name=file_name)
        await speech.stream_to_file(file_path)

    return file_path


async def speak_and_spell(
    context: CommandContext,
    prompt: str,
) -> Tuple[str, Path]:
    """
    Create a new response and WAV file in one nice function.
    """
    openai_client = await get_openai_client(guild_id=context.guild_id)

    response = await new_response(context=context, prompt=prompt, openai_client=openai_client)

    tts = response.output_text

    file_path = await generate_speech(
        context=context, tts=tts, file_name=f"{response.id}.wav", openai_client=openai_client
    )

    return tts, file_path


def content_path(context: CommandContext, file_name: str) -> Path:
    """
    Create a path to store the content generated by OpenAI.
    """
    ts = datetime.now().strftime(format="%Y-%m-%d - %A")
    dir_path = Path(f"generated_content/guild_{context.guild_id}/{ts}/{context.command_name}")
    dir_path.mkdir(parents=True, exist_ok=True)
    return dir_path / file_name


def check_model_limit(context: CommandContext, usage_tracker: dict) -> bool:
    """
    A function to check if a model's usage has reached a limit specified in the config
    """
    config = get_config()
    model: str = context.params.get("model")
    usage_limits = {model: int(count) for model, count in config["OPENAI_MODEL_LIMITS"].items()}
    limit = usage_limits.get(model)

    # do not limit models that don't have a specified limit in the config
    if not limit:
        return True

    today = datetime.now().strftime("%Y-%m-%d")

    # create a blank dictionary for a guild if it isn't present in the map already
    if context.guild_id not in usage_tracker:
        usage_tracker[context.guild_id] = {}

    # initialize a model usage dict for the limited-use model
    if model not in usage_tracker[context.guild_id]:
        usage_tracker[context.guild_id][model] = {"count": 0, "last_reset": today, "limit": limit}

    record = usage_tracker[context.guild_id][model]

    # reset the usage on a new day
    if record["last_reset"] != today:
        record["count"] = 0
        record["last_reset"] = today
        record["limit"] = limit

    if record["count"] >= limit:
        return False  # Limit reached

    # increment the count
    record["count"] += 1

    return True
